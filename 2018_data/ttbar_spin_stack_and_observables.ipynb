{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "884ee0fe",
   "metadata": {},
   "source": [
    "# tt̄ spin observables: Data/MC stacks + P,C,D extraction\n",
    "This notebook stacks Data vs MC histograms and extracts spin observables from cosine histograms.\n",
    "\n",
    "**Features**\n",
    "- Uses PyROOT when available; otherwise falls back to uproot.\n",
    "- Scales each MC by `xsec*lumi/n_events` from `plots/count`.\n",
    "- Plots stacks with mplhep; highlights TTTo2L2Nu in red.\n",
    "- Extracts `<cosθ+> → P_a`, `<cosθ+ cosθ-> → C_aa`, and `D=(Ckk+Crr+Cnn)/3` per channel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef70e4f3",
   "metadata": {},
   "source": [
    "## 0) Setup & imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86fb720f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend: PyROOT\n"
     ]
    }
   ],
   "source": [
    "import os, math, numpy as np, sys, csv\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "USE_ROOT = True\n",
    "try:\n",
    "    import ROOT\n",
    "    ROOT.gErrorIgnoreLevel = ROOT.kError\n",
    "    ROOT.TH1.SetDefaultSumw2(True)\n",
    "except Exception as e:\n",
    "    USE_ROOT = False\n",
    "    import uproot\n",
    "out_dir = 'compare_plots_mpl_stack'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "print('Backend:', 'PyROOT' if USE_ROOT else 'uproot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4636b10b",
   "metadata": {},
   "source": [
    "## 1) File lists, xsecs, lumi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59284d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = [\n",
    "    'DoubleMuon_Data_2018.root',\n",
    "    'MuonEG_Data_2018.root',\n",
    "    'EGamma_Data_2018.root',\n",
    "    'SingleMuon_Data_2018.root',\n",
    "]\n",
    "mc_files = [\n",
    "    'DYJetsToLL_M-10to50_MC_2018.root',\n",
    "    'DYJetsToLL_M-50_MC_2018.root',\n",
    "    'ST_s-channel_MC_2018.root',\n",
    "    'ST_t-channel_antitop_MC_2018.root',\n",
    "    'ST_t-channel_top_MC_2018.root',\n",
    "    'ST_tW_antitop_MC_2018.root',\n",
    "    'ST_tW_top_MC_2018.root',\n",
    "    'TTTo2L2Nu_MC_2018.root',\n",
    "    'TTToHadronic_MC_2018.root',\n",
    "    'TTToSemiLeptonic_MC_2018.root',\n",
    "    'WJetsToLNu_MC_2018.root',\n",
    "    'WW_MC_2018.root',\n",
    "    'WZ_MC_2018.root',\n",
    "    'ZZ_MC_2018.root',\n",
    "]\n",
    "cross_sections_pb = {\n",
    "    'DYJetsToLL_M-10to50_MC_2018.root': 18610.0,\n",
    "    'DYJetsToLL_M-50_MC_2018.root':    6077.22,\n",
    "    'ST_s-channel_MC_2018.root':       3.36,\n",
    "    'ST_t-channel_antitop_MC_2018.root': 80.95,\n",
    "    'ST_t-channel_top_MC_2018.root':   136.02,\n",
    "    'ST_tW_antitop_MC_2018.root':      34.91,\n",
    "    'ST_tW_top_MC_2018.root':          34.97,\n",
    "    'TTTo2L2Nu_MC_2018.root':          87.4,\n",
    "    'TTToHadronic_MC_2018.root':       380.0,\n",
    "    'TTToSemiLeptonic_MC_2018.root':   364.0,\n",
    "    'WJetsToLNu_MC_2018.root':         61526.0,\n",
    "    'WW_MC_2018.root':                 118.7,\n",
    "    'WZ_MC_2018.root':                 47.13,\n",
    "    'ZZ_MC_2018.root':                 16.523,\n",
    "}\n",
    "luminosity_pb = 59.740 * 1000.0\n",
    "alpha_l = 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a28c4a",
   "metadata": {},
   "source": [
    "## 1.5) Histogram discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "530e0c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 257 histograms\n"
     ]
    }
   ],
   "source": [
    "def get_hist_names(filename, directory='plots'):\n",
    "    if USE_ROOT:\n",
    "        f = ROOT.TFile.Open(filename)\n",
    "        if not f or f.IsZombie():\n",
    "            return []\n",
    "        if not f.GetDirectory(directory):\n",
    "            f.Close(); return []\n",
    "        f.cd(directory)\n",
    "        names = [k.GetName() for k in ROOT.gDirectory.GetListOfKeys()]\n",
    "        f.Close()\n",
    "        return names\n",
    "    else:\n",
    "        with uproot.open(filename) as f:\n",
    "            if directory not in f:\n",
    "                return []\n",
    "            return [k.split(';')[0] for k in f[directory].keys()]\n",
    "\n",
    "hist_names = get_hist_names(mc_files[0])\n",
    "prefixes = ('mumu','ee','emu','combine','numberof','ll','all')\n",
    "hist_names = [h for h in hist_names if any(h.startswith(p) for p in prefixes)]\n",
    "print('Found', len(hist_names),'histograms')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d790e5a",
   "metadata": {},
   "source": [
    "## 2) Helpers to read/scale and convert to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e06a851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hist(file_name, hist_path):\n",
    "    if USE_ROOT:\n",
    "        f = ROOT.TFile.Open(file_name)\n",
    "        if not f or f.IsZombie():\n",
    "            return None\n",
    "        h = f.Get(hist_path)\n",
    "        if h:\n",
    "            h = h.Clone(f'tmp_{os.path.basename(file_name)}_{h.GetName()}')\n",
    "            h.SetDirectory(0)\n",
    "        f.Close(); return h\n",
    "    else:\n",
    "        with uproot.open(file_name) as f:\n",
    "            if hist_path not in f:\n",
    "                return (None, None)\n",
    "            h = f[hist_path]\n",
    "            try:\n",
    "                edges = h.axis().edges(); counts = h.values()\n",
    "            except Exception:\n",
    "                counts, edges = h.to_numpy()\n",
    "            return (np.asarray(edges), np.asarray(counts))\n",
    "\n",
    "def read_count(file_name, count_path='plots/count'):\n",
    "    if USE_ROOT:\n",
    "        f = ROOT.TFile.Open(file_name)\n",
    "        if not f or f.IsZombie():\n",
    "            return 0.0\n",
    "        cnt = f.Get(count_path)\n",
    "        n = cnt.GetSumOfWeights() if cnt else 0.0\n",
    "        f.Close(); return float(n)\n",
    "    else:\n",
    "        with uproot.open(file_name) as f:\n",
    "            if count_path not in f: return 0.0\n",
    "            cnt = f[count_path]\n",
    "            try:\n",
    "                return float(cnt.values().sum())\n",
    "            except Exception:\n",
    "                try:\n",
    "                    return float(cnt.member('fTsumw'))\n",
    "                except Exception:\n",
    "                    return 0.0\n",
    "\n",
    "def hist_to_numpy_root(h):\n",
    "    nb = h.GetNbinsX()\n",
    "    edges = np.array([h.GetBinLowEdge(i) for i in range(1, nb+1)] + [h.GetBinLowEdge(nb)+h.GetBinWidth(nb)])\n",
    "    counts = np.array([h.GetBinContent(i) for i in range(1, nb+1)])\n",
    "    return edges, counts\n",
    "\n",
    "def stack_mc_numpy(hname):\n",
    "    hist_path = f'plots/{hname}'\n",
    "    arrays, labels = [], []\n",
    "    edges_common = None\n",
    "    mc_sum_hist = None\n",
    "    for fn in mc_files:\n",
    "        xsec = cross_sections_pb.get(fn, 1.0)\n",
    "        if USE_ROOT:\n",
    "            h = read_hist(fn, hist_path)\n",
    "            if not h: continue\n",
    "            n_evt = read_count(fn)\n",
    "            if n_evt <= 0: continue\n",
    "            scale = (xsec * luminosity_pb) / n_evt\n",
    "            h.Sumw2(); h.Scale(scale)\n",
    "            edges, counts = hist_to_numpy_root(h)\n",
    "            if edges_common is None: edges_common = edges\n",
    "            arrays.append(counts); labels.append(os.path.splitext(fn)[0])\n",
    "            if mc_sum_hist is None:\n",
    "                mc_sum_hist = h.Clone('mc_sum'); mc_sum_hist.SetDirectory(0)\n",
    "            else:\n",
    "                mc_sum_hist.Add(h)\n",
    "        else:\n",
    "            edges, counts = read_hist(fn, hist_path)\n",
    "            if edges is None: continue\n",
    "            n_evt = read_count(fn)\n",
    "            if n_evt <= 0: continue\n",
    "            scale = (xsec * luminosity_pb) / n_evt\n",
    "            counts = counts * scale\n",
    "            if edges_common is None: edges_common = edges\n",
    "            arrays.append(counts); labels.append(os.path.splitext(fn)[0])\n",
    "    if edges_common is None or len(arrays)==0:\n",
    "        return None, [], [], None, None\n",
    "    arrays = [np.asarray(a) for a in arrays]\n",
    "    mc_sum_counts = np.sum(arrays, axis=0) if len(arrays)>0 else None\n",
    "    return edges_common, arrays, labels, mc_sum_counts, mc_sum_hist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d838ad",
   "metadata": {},
   "source": [
    "## 3) Combine data helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4fd5af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(hname):\n",
    "    hist_path = f'plots/{hname}'\n",
    "    if USE_ROOT:\n",
    "        data_hist = None\n",
    "        for fn in data_files:\n",
    "            h = read_hist(fn, hist_path)\n",
    "            if not h: continue\n",
    "            if data_hist is None:\n",
    "                data_hist = h.Clone('data_sum'); data_hist.SetDirectory(0)\n",
    "            else:\n",
    "                data_hist.Add(h)\n",
    "        if data_hist is None: return (None, None)\n",
    "        return hist_to_numpy_root(data_hist)\n",
    "    else:\n",
    "        edges, counts = None, None\n",
    "        for fn in data_files:\n",
    "            e, c = read_hist(fn, hist_path)\n",
    "            if e is None: continue\n",
    "            if edges is None:\n",
    "                edges, counts = e, c.copy()\n",
    "            else:\n",
    "                if not np.allclose(edges, e):\n",
    "                    raise RuntimeError('Inconsistent data binning')\n",
    "                counts += c\n",
    "        return edges, counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d00c66c",
   "metadata": {},
   "source": [
    "## 4) cosθ helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "749ac060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cos_hist(hname):\n",
    "    keys = [\n",
    "        'cosThetaPlus_k','cosThetaMinus_k','cosThetaPlus_k_times_Minus_k',\n",
    "        'cosThetaPlus_r','cosThetaMinus_r','cosThetaPlus_r_times_Minus_r',\n",
    "        'cosThetaPlus_n','cosThetaMinus_n','cosThetaPlus_n_times_Minus_n',\n",
    "    ]\n",
    "    return any(k in hname for k in keys)\n",
    "\n",
    "def axis_from_name(hname):\n",
    "    if '_k' in hname: return 'k'\n",
    "    if '_r' in hname: return 'r'\n",
    "    if '_n' in hname: return 'n'\n",
    "    return None\n",
    "\n",
    "def channel_from_name(hname):\n",
    "    for ch in ['ee','mumu','emu','all']:\n",
    "        if hname.startswith(ch+'_'): return ch\n",
    "    return 'all'\n",
    "\n",
    "def mean_from_counts(edges, counts):\n",
    "    centers = 0.5*(edges[:-1]+edges[1:])\n",
    "    tot = counts.sum()\n",
    "    if tot <= 0: return float('nan')\n",
    "    return float(np.dot(centers, counts)/tot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc472c2",
   "metadata": {},
   "source": [
    "## 5) Main loop: stacks + observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5612ef1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: compare_plots_mpl_stack/spin_observables.csv\n"
     ]
    }
   ],
   "source": [
    "plt.style.use(hep.style.CMS)\n",
    "results = []\n",
    "for hname in hist_names:\n",
    "    # 1D guard (best-effort for uproot case)\n",
    "    # Data\n",
    "    edges, dat_counts = combine_data(hname)\n",
    "    if edges is None:\n",
    "        print('[skip] No data for', hname); continue\n",
    "    dat_err = np.sqrt(np.clip(dat_counts,0,None))\n",
    "    centers = 0.5*(edges[:-1]+edges[1:])\n",
    "\n",
    "    # MC\n",
    "    edges_mc, mc_arrays, mc_labels, mc_sum_counts, mc_sum_hist = stack_mc_numpy(hname)\n",
    "    if edges_mc is None:\n",
    "        print('[skip] No MC for', hname); continue\n",
    "\n",
    "    # Colors\n",
    "    cmap = plt.get_cmap('tab20')\n",
    "    others = [lbl for lbl in mc_labels if lbl != 'TTTo2L2Nu_MC_2018']\n",
    "    color_map = {lbl: cmap(i/max(1,len(others)-1)) for i,lbl in enumerate(others)}\n",
    "    color_map['TTTo2L2Nu_MC_2018'] = 'red'\n",
    "    mc_colors = [color_map[lbl] for lbl in mc_labels]\n",
    "\n",
    "    # Plot\n",
    "    fig, (ax, axr) = plt.subplots(nrows=2, sharex=True,\n",
    "        gridspec_kw={'height_ratios':[3,1],'hspace':0.05}, figsize=(10,8), dpi=150)\n",
    "    hep.histplot(mc_arrays, bins=edges, stack=True, histtype='fill', label=mc_labels, color=mc_colors, ax=ax)\n",
    "    ax.errorbar(centers, dat_counts, yerr=dat_err, fmt='o', color='black', label='Data')\n",
    "    ax.set_ylabel('Events / bin')\n",
    "    hep.cms.label('Private Work', data=True, lumi=59.8, ax=ax)\n",
    "    ax.legend(loc='upper right', prop={'size':8}, handletextpad=0.2, labelspacing=0.2, columnspacing=0.5)\n",
    "\n",
    "    mc_sum = mc_sum_counts\n",
    "    mask = mc_sum > 0\n",
    "    ratio = np.divide(dat_counts, mc_sum, out=np.zeros_like(dat_counts), where=mask)\n",
    "    ratio_err = np.divide(dat_err, mc_sum, out=np.zeros_like(dat_err), where=mask)\n",
    "    axr.errorbar(centers[mask], ratio[mask], yerr=ratio_err[mask], fmt='o', color='black')\n",
    "    axr.axhline(1, color='gray', linestyle='--', linewidth=1)\n",
    "    axr.set_ylabel('Data/MC'); axr.set_xlabel(hname); axr.set_ylim(0.5,1.5)\n",
    "\n",
    "    fig.savefig(f\"{out_dir}/stack_{hname}.png\"); plt.close(fig)\n",
    "\n",
    "    # Observables\n",
    "    if is_cos_hist(hname):\n",
    "        ch = channel_from_name(hname)\n",
    "        axis = axis_from_name(hname)\n",
    "        mean_data = mean_from_counts(edges, dat_counts)\n",
    "        if USE_ROOT and mc_sum_hist is not None:\n",
    "            mean_mc = float(mc_sum_hist.GetMean())\n",
    "        else:\n",
    "            mean_mc = mean_from_counts(edges, mc_sum_counts)\n",
    "        if 'times_Minus_' in hname:\n",
    "            C_data = (9.0/(alpha_l**2))*mean_data\n",
    "            C_mc   = (9.0/(alpha_l**2))*mean_mc\n",
    "            results.append([hname,ch,axis,'Caa',mean_data,mean_mc,C_data,C_mc])\n",
    "        elif 'cosThetaPlus_' in hname:\n",
    "            P_data = (3.0/alpha_l)*mean_data\n",
    "            P_mc   = (3.0/alpha_l)*mean_mc\n",
    "            results.append([hname,ch,axis,'Pa',mean_data,mean_mc,P_data,P_mc])\n",
    "\n",
    "# Build D per channel\n",
    "C_map_data = {ch:{'k':None,'r':None,'n':None} for ch in ['ee','mumu','emu','all']}\n",
    "C_map_mc   = {ch:{'k':None,'r':None,'n':None} for ch in ['ee','mumu','emu','all']}\n",
    "for hname,ch,axis,kind,mean_d,mean_m,val_d,val_m in results:\n",
    "    if kind=='Caa':\n",
    "        C_map_data[ch][axis]=val_d; C_map_mc[ch][axis]=val_m\n",
    "for ch in C_map_data:\n",
    "    cds=C_map_data[ch]; cms=C_map_mc[ch]\n",
    "    if all(v is not None for v in cds.values()):\n",
    "        D_data=(cds['k']+cds['r']+cds['n'])/3.0\n",
    "        results.append([f'{ch}_D',ch,'sum','D',float('nan'),float('nan'),D_data,float('nan')])\n",
    "    if all(v is not None for v in cms.values()):\n",
    "        D_mc=(cms['k']+cms['r']+cms['n'])/3.0\n",
    "        results.append([f'{ch}_D_mc',ch,'sum','D_MC',float('nan'),float('nan'),float('nan'),D_mc])\n",
    "\n",
    "# Save CSV\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results, columns=['hname','channel','axis','kind','mean_data','mean_mc','value_data','value_mc'])\n",
    "csv_path = f\"{out_dir}/spin_observables.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print('Saved:', csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d706a18a",
   "metadata": {},
   "source": [
    "## 6) Preview CSV (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7923878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hname</th>\n",
       "      <th>channel</th>\n",
       "      <th>axis</th>\n",
       "      <th>kind</th>\n",
       "      <th>mean_data</th>\n",
       "      <th>mean_mc</th>\n",
       "      <th>value_data</th>\n",
       "      <th>value_mc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ee_cosThetaPlus_k</td>\n",
       "      <td>ee</td>\n",
       "      <td>k</td>\n",
       "      <td>Pa</td>\n",
       "      <td>-0.038832</td>\n",
       "      <td>-0.156229</td>\n",
       "      <td>-0.116496</td>\n",
       "      <td>-0.468688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ee_cosThetaPlus_k_times_Minus_k</td>\n",
       "      <td>ee</td>\n",
       "      <td>k</td>\n",
       "      <td>Caa</td>\n",
       "      <td>0.052737</td>\n",
       "      <td>0.012439</td>\n",
       "      <td>0.474631</td>\n",
       "      <td>0.111950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ee_cosThetaPlus_r</td>\n",
       "      <td>ee</td>\n",
       "      <td>r</td>\n",
       "      <td>Pa</td>\n",
       "      <td>0.006837</td>\n",
       "      <td>-0.026162</td>\n",
       "      <td>0.020511</td>\n",
       "      <td>-0.078486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ee_cosThetaPlus_r_times_Minus_r</td>\n",
       "      <td>ee</td>\n",
       "      <td>r</td>\n",
       "      <td>Caa</td>\n",
       "      <td>0.027288</td>\n",
       "      <td>0.036251</td>\n",
       "      <td>0.245592</td>\n",
       "      <td>0.326259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ee_cosThetaPlus_n</td>\n",
       "      <td>ee</td>\n",
       "      <td>n</td>\n",
       "      <td>Pa</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.091750</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>-0.275250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ee_cosThetaPlus_n_times_Minus_n</td>\n",
       "      <td>ee</td>\n",
       "      <td>n</td>\n",
       "      <td>Caa</td>\n",
       "      <td>0.035387</td>\n",
       "      <td>0.071179</td>\n",
       "      <td>0.318485</td>\n",
       "      <td>0.640610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mumu_cosThetaPlus_k</td>\n",
       "      <td>mumu</td>\n",
       "      <td>k</td>\n",
       "      <td>Pa</td>\n",
       "      <td>-0.057023</td>\n",
       "      <td>-0.242744</td>\n",
       "      <td>-0.171068</td>\n",
       "      <td>-0.728231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mumu_cosThetaPlus_k_times_Minus_k</td>\n",
       "      <td>mumu</td>\n",
       "      <td>k</td>\n",
       "      <td>Caa</td>\n",
       "      <td>0.052643</td>\n",
       "      <td>0.103421</td>\n",
       "      <td>0.473783</td>\n",
       "      <td>0.930789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mumu_cosThetaPlus_r</td>\n",
       "      <td>mumu</td>\n",
       "      <td>r</td>\n",
       "      <td>Pa</td>\n",
       "      <td>0.004253</td>\n",
       "      <td>-0.007646</td>\n",
       "      <td>0.012759</td>\n",
       "      <td>-0.022938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mumu_cosThetaPlus_r_times_Minus_r</td>\n",
       "      <td>mumu</td>\n",
       "      <td>r</td>\n",
       "      <td>Caa</td>\n",
       "      <td>0.032841</td>\n",
       "      <td>0.062963</td>\n",
       "      <td>0.295567</td>\n",
       "      <td>0.566669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mumu_cosThetaPlus_n</td>\n",
       "      <td>mumu</td>\n",
       "      <td>n</td>\n",
       "      <td>Pa</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.008932</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.026797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mumu_cosThetaPlus_n_times_Minus_n</td>\n",
       "      <td>mumu</td>\n",
       "      <td>n</td>\n",
       "      <td>Caa</td>\n",
       "      <td>0.030452</td>\n",
       "      <td>0.112493</td>\n",
       "      <td>0.274068</td>\n",
       "      <td>1.012441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>emu_cosThetaPlus_k</td>\n",
       "      <td>emu</td>\n",
       "      <td>k</td>\n",
       "      <td>Pa</td>\n",
       "      <td>-0.016767</td>\n",
       "      <td>-0.164694</td>\n",
       "      <td>-0.050300</td>\n",
       "      <td>-0.494083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>emu_cosThetaPlus_k_times_Minus_k</td>\n",
       "      <td>emu</td>\n",
       "      <td>k</td>\n",
       "      <td>Caa</td>\n",
       "      <td>0.031587</td>\n",
       "      <td>0.088854</td>\n",
       "      <td>0.284280</td>\n",
       "      <td>0.799685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>emu_cosThetaPlus_r</td>\n",
       "      <td>emu</td>\n",
       "      <td>r</td>\n",
       "      <td>Pa</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>-0.106079</td>\n",
       "      <td>0.010530</td>\n",
       "      <td>-0.318236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>emu_cosThetaPlus_r_times_Minus_r</td>\n",
       "      <td>emu</td>\n",
       "      <td>r</td>\n",
       "      <td>Caa</td>\n",
       "      <td>0.008110</td>\n",
       "      <td>-0.058573</td>\n",
       "      <td>0.072990</td>\n",
       "      <td>-0.527153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>emu_cosThetaPlus_n</td>\n",
       "      <td>emu</td>\n",
       "      <td>n</td>\n",
       "      <td>Pa</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>-0.079587</td>\n",
       "      <td>0.006224</td>\n",
       "      <td>-0.238762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>emu_cosThetaPlus_n_times_Minus_n</td>\n",
       "      <td>emu</td>\n",
       "      <td>n</td>\n",
       "      <td>Caa</td>\n",
       "      <td>0.028344</td>\n",
       "      <td>0.009894</td>\n",
       "      <td>0.255098</td>\n",
       "      <td>0.089045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>all_cosThetaPlus_k</td>\n",
       "      <td>all</td>\n",
       "      <td>k</td>\n",
       "      <td>Pa</td>\n",
       "      <td>-0.033124</td>\n",
       "      <td>-0.185978</td>\n",
       "      <td>-0.099372</td>\n",
       "      <td>-0.557934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>all_cosThetaPlus_k_times_Minus_k</td>\n",
       "      <td>all</td>\n",
       "      <td>k</td>\n",
       "      <td>Caa</td>\n",
       "      <td>0.041706</td>\n",
       "      <td>0.072978</td>\n",
       "      <td>0.375351</td>\n",
       "      <td>0.656804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                hname channel axis kind  mean_data   mean_mc  \\\n",
       "0                   ee_cosThetaPlus_k      ee    k   Pa  -0.038832 -0.156229   \n",
       "1     ee_cosThetaPlus_k_times_Minus_k      ee    k  Caa   0.052737  0.012439   \n",
       "2                   ee_cosThetaPlus_r      ee    r   Pa   0.006837 -0.026162   \n",
       "3     ee_cosThetaPlus_r_times_Minus_r      ee    r  Caa   0.027288  0.036251   \n",
       "4                   ee_cosThetaPlus_n      ee    n   Pa   0.000013 -0.091750   \n",
       "5     ee_cosThetaPlus_n_times_Minus_n      ee    n  Caa   0.035387  0.071179   \n",
       "6                 mumu_cosThetaPlus_k    mumu    k   Pa  -0.057023 -0.242744   \n",
       "7   mumu_cosThetaPlus_k_times_Minus_k    mumu    k  Caa   0.052643  0.103421   \n",
       "8                 mumu_cosThetaPlus_r    mumu    r   Pa   0.004253 -0.007646   \n",
       "9   mumu_cosThetaPlus_r_times_Minus_r    mumu    r  Caa   0.032841  0.062963   \n",
       "10                mumu_cosThetaPlus_n    mumu    n   Pa   0.000854  0.008932   \n",
       "11  mumu_cosThetaPlus_n_times_Minus_n    mumu    n  Caa   0.030452  0.112493   \n",
       "12                 emu_cosThetaPlus_k     emu    k   Pa  -0.016767 -0.164694   \n",
       "13   emu_cosThetaPlus_k_times_Minus_k     emu    k  Caa   0.031587  0.088854   \n",
       "14                 emu_cosThetaPlus_r     emu    r   Pa   0.003510 -0.106079   \n",
       "15   emu_cosThetaPlus_r_times_Minus_r     emu    r  Caa   0.008110 -0.058573   \n",
       "16                 emu_cosThetaPlus_n     emu    n   Pa   0.002075 -0.079587   \n",
       "17   emu_cosThetaPlus_n_times_Minus_n     emu    n  Caa   0.028344  0.009894   \n",
       "18                 all_cosThetaPlus_k     all    k   Pa  -0.033124 -0.185978   \n",
       "19   all_cosThetaPlus_k_times_Minus_k     all    k  Caa   0.041706  0.072978   \n",
       "\n",
       "    value_data  value_mc  \n",
       "0    -0.116496 -0.468688  \n",
       "1     0.474631  0.111950  \n",
       "2     0.020511 -0.078486  \n",
       "3     0.245592  0.326259  \n",
       "4     0.000038 -0.275250  \n",
       "5     0.318485  0.640610  \n",
       "6    -0.171068 -0.728231  \n",
       "7     0.473783  0.930789  \n",
       "8     0.012759 -0.022938  \n",
       "9     0.295567  0.566669  \n",
       "10    0.002563  0.026797  \n",
       "11    0.274068  1.012441  \n",
       "12   -0.050300 -0.494083  \n",
       "13    0.284280  0.799685  \n",
       "14    0.010530 -0.318236  \n",
       "15    0.072990 -0.527153  \n",
       "16    0.006224 -0.238762  \n",
       "17    0.255098  0.089045  \n",
       "18   -0.099372 -0.557934  \n",
       "19    0.375351  0.656804  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd, os\n",
    "csv_path = f\"{out_dir}/spin_observables.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    display(pd.read_csv(csv_path).head(20))\n",
    "else:\n",
    "    print('Run the previous cell after pointing to real files to produce the CSV.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4768b91-07fa-485f-b025-8da426375cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44efb4f-e11d-42cf-8ed5-4393b1a93bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
