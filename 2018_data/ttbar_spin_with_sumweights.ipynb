{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2e2c0c",
   "metadata": {},
   "source": [
    "# ttÌ„ spin observables: stacks + P,C,D (using explicit sumWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aceb73c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend: PyROOT\n"
     ]
    }
   ],
   "source": [
    "import os, math, numpy as np, sys, csv\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "USE_ROOT = True\n",
    "try:\n",
    "    import ROOT\n",
    "    ROOT.gErrorIgnoreLevel = ROOT.kError\n",
    "    ROOT.TH1.SetDefaultSumw2(True)\n",
    "except Exception as e:\n",
    "    USE_ROOT = False\n",
    "    import uproot\n",
    "out_dir = 'compare_plots_mpl_stack'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "print('Backend:', 'PyROOT' if USE_ROOT else 'uproot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af3e36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = [\n",
    "    'DoubleMuon_Data_2018.root',\n",
    "    'MuonEG_Data_2018.root',\n",
    "    'EGamma_Data_2018.root',\n",
    "    'SingleMuon_Data_2018.root',\n",
    "]\n",
    "mc_files = [\n",
    "    'DYJetsToLL_M-10to50_MC_2018.root',\n",
    "    'DYJetsToLL_M-50_MC_2018.root',\n",
    "    'ST_s-channel_MC_2018.root',\n",
    "    'ST_t-channel_antitop_MC_2018.root',\n",
    "    'ST_t-channel_top_MC_2018.root',\n",
    "    'ST_tW_antitop_MC_2018.root',\n",
    "    'ST_tW_top_MC_2018.root',\n",
    "    'TTTo2L2Nu_MC_2018.root',\n",
    "    'TTToHadronic_MC_2018.root',\n",
    "    'TTToSemiLeptonic_MC_2018.root',\n",
    "    'WJetsToLNu_MC_2018.root',\n",
    "    'WW_MC_2018.root',\n",
    "    'WZ_MC_2018.root',\n",
    "    'ZZ_MC_2018.root',\n",
    "]\n",
    "cross_sections_pb = {\n",
    "    'DYJetsToLL_M-10to50_MC_2018.root': 18610.0,\n",
    "    'DYJetsToLL_M-50_MC_2018.root':    6077.22,\n",
    "    'ST_s-channel_MC_2018.root':       3.36,\n",
    "    'ST_t-channel_antitop_MC_2018.root': 80.95,\n",
    "    'ST_t-channel_top_MC_2018.root':   136.02,\n",
    "    'ST_tW_antitop_MC_2018.root':      34.91,\n",
    "    'ST_tW_top_MC_2018.root':          34.97,\n",
    "    'TTTo2L2Nu_MC_2018.root':          87.4,\n",
    "    'TTToHadronic_MC_2018.root':       380.0,\n",
    "    'TTToSemiLeptonic_MC_2018.root':   364.0,\n",
    "    'WJetsToLNu_MC_2018.root':         61526.0,\n",
    "    'WW_MC_2018.root':                 118.7,\n",
    "    'WZ_MC_2018.root':                 47.13,\n",
    "    'ZZ_MC_2018.root':                 16.523,\n",
    "}\n",
    "sum_weights = {\n",
    "    'DYJetsToLL_M-50_MC_2018.root':        131572454.00,\n",
    "    'TTToSemiLeptonic_MC_2018.root':       472557630.00,\n",
    "    'DYJetsToLL_M-10to50_MC_2018.root':    74373706.00,\n",
    "    'ZZ_MC_2018.root':                      3526000.00,\n",
    "    'TTToHadronic_MC_2018.root':          331506194.00,\n",
    "    'ST_t-channel_antitop_MC_2018.root':   90022642.00,\n",
    "    'ST_s-channel_MC_2018.root':           12607741.00,\n",
    "    'TTTo2L2Nu_MC_2018.root':             143848848.00,\n",
    "    'ST_tW_top_MC_2018.root':               7955614.00,\n",
    "    'WJetsToLNu_MC_2018.root':             79645994.00,\n",
    "    'ST_tW_antitop_MC_2018.root':           7748690.00,\n",
    "    'ST_t-channel_top_MC_2018.root':      167111718.00,\n",
    "    'WW_MC_2018.root':                     15679000.00,\n",
    "    'WZ_MC_2018.root':                      7940000.00,\n",
    "}\n",
    "luminosity_pb = 59.740 * 1000.0\n",
    "alpha_l = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "198a6182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 257 histograms\n"
     ]
    }
   ],
   "source": [
    "def get_hist_names(filename, directory='plots'):\n",
    "    if USE_ROOT:\n",
    "        f = ROOT.TFile.Open(filename)\n",
    "        if not f or f.IsZombie(): return []\n",
    "        if not f.GetDirectory(directory): f.Close(); return []\n",
    "        f.cd(directory)\n",
    "        names = [k.GetName() for k in ROOT.gDirectory.GetListOfKeys()]\n",
    "        f.Close(); return names\n",
    "    else:\n",
    "        with uproot.open(filename) as f:\n",
    "            if directory not in f: return []\n",
    "            return [k.split(';')[0] for k in f[directory].keys()]\n",
    "\n",
    "hist_names = get_hist_names(mc_files[0])\n",
    "prefixes = ('mumu','ee','emu','combine','numberof','ll','all')\n",
    "hist_names = [h for h in hist_names if any(h.startswith(p) for p in prefixes)]\n",
    "print('Found', len(hist_names), 'histograms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7844dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hist(file_name, hist_path):\n",
    "    if USE_ROOT:\n",
    "        f = ROOT.TFile.Open(file_name)\n",
    "        if not f or f.IsZombie(): return None\n",
    "        h = f.Get(hist_path)\n",
    "        if h:\n",
    "            h = h.Clone(f'tmp_{os.path.basename(file_name)}_{h.GetName()}')\n",
    "            h.SetDirectory(0)\n",
    "        f.Close(); return h\n",
    "    else:\n",
    "        with uproot.open(file_name) as f:\n",
    "            if hist_path not in f: return (None, None)\n",
    "            h = f[hist_path]\n",
    "            try:\n",
    "                edges = h.axis().edges(); counts = h.values()\n",
    "            except Exception:\n",
    "                counts, edges = h.to_numpy()\n",
    "            return (np.asarray(edges), np.asarray(counts))\n",
    "\n",
    "def hist_to_numpy_root(h):\n",
    "    nb = h.GetNbinsX()\n",
    "    edges = np.array([h.GetBinLowEdge(i) for i in range(1, nb+1)] + [h.GetBinLowEdge(nb)+h.GetBinWidth(nb)])\n",
    "    counts = np.array([h.GetBinContent(i) for i in range(1, nb+1)])\n",
    "    return edges, counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b275671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scale_factor(mc_filename):\n",
    "    xsec = cross_sections_pb.get(mc_filename, 1.0)\n",
    "    n_evt = sum_weights.get(mc_filename, None)\n",
    "    if n_evt is None or n_evt <= 0:\n",
    "        print(f'[warn] sumWeights missing or non-positive for {mc_filename}; skipping this sample.')\n",
    "        return 0.0\n",
    "    return (xsec * luminosity_pb) / n_evt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89fd48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_mc_numpy(hname):\n",
    "    hist_path = f'plots/{hname}'\n",
    "    arrays, labels = [], []\n",
    "    edges_common = None\n",
    "    mc_sum_hist = None\n",
    "    for fn in mc_files:\n",
    "        scale = get_scale_factor(fn)\n",
    "        if scale <= 0: continue\n",
    "        if USE_ROOT:\n",
    "            h = read_hist(fn, hist_path)\n",
    "            if not h: continue\n",
    "            h.Sumw2(); h.Scale(scale)\n",
    "            edges, counts = hist_to_numpy_root(h)\n",
    "            if edges_common is None: edges_common = edges\n",
    "            arrays.append(counts); labels.append(os.path.splitext(fn)[0])\n",
    "            if mc_sum_hist is None:\n",
    "                mc_sum_hist = h.Clone('mc_sum'); mc_sum_hist.SetDirectory(0)\n",
    "            else:\n",
    "                mc_sum_hist.Add(h)\n",
    "        else:\n",
    "            edges, counts = read_hist(fn, hist_path)\n",
    "            if edges is None: continue\n",
    "            counts = counts * scale\n",
    "            if edges_common is None: edges_common = edges\n",
    "            arrays.append(counts); labels.append(os.path.splitext(fn)[0])\n",
    "    if edges_common is None or len(arrays)==0:\n",
    "        return None, [], [], None, None\n",
    "    arrays = [np.asarray(a) for a in arrays]\n",
    "    mc_sum_counts = np.sum(arrays, axis=0) if len(arrays)>0 else None\n",
    "    return edges_common, arrays, labels, mc_sum_counts, mc_sum_hist\n",
    "\n",
    "def combine_data(hname):\n",
    "    hist_path = f'plots/{hname}'\n",
    "    if USE_ROOT:\n",
    "        data_hist = None\n",
    "        for fn in data_files:\n",
    "            h = read_hist(fn, hist_path)\n",
    "            if not h: continue\n",
    "            if data_hist is None:\n",
    "                data_hist = h.Clone('data_sum'); data_hist.SetDirectory(0)\n",
    "            else:\n",
    "                data_hist.Add(h)\n",
    "        if data_hist is None: return (None, None)\n",
    "        return hist_to_numpy_root(data_hist)\n",
    "    else:\n",
    "        edges, counts = None, None\n",
    "        for fn in data_files:\n",
    "            e, c = read_hist(fn, hist_path)\n",
    "            if e is None: continue\n",
    "            if edges is None:\n",
    "                edges, counts = e, c.copy()\n",
    "            else:\n",
    "                if not np.allclose(edges, e):\n",
    "                    raise RuntimeError('Inconsistent data binning')\n",
    "                counts += c\n",
    "        return edges, counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c0da013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cos_hist(hname):\n",
    "    keys = [\n",
    "        'cosThetaPlus_k','cosThetaMinus_k','cosThetaPlus_k_times_Minus_k',\n",
    "        'cosThetaPlus_r','cosThetaMinus_r','cosThetaPlus_r_times_Minus_r',\n",
    "        'cosThetaPlus_n','cosThetaMinus_n','cosThetaPlus_n_times_Minus_n',\n",
    "    ]\n",
    "    return any(k in hname for k in keys)\n",
    "def axis_from_name(hname):\n",
    "    if '_k' in hname: return 'k'\n",
    "    if '_r' in hname: return 'r'\n",
    "    if '_n' in hname: return 'n'\n",
    "    return None\n",
    "def channel_from_name(hname):\n",
    "    for ch in ['ee','mumu','emu','all']:\n",
    "        if hname.startswith(ch+'_'): return ch\n",
    "    return 'all'\n",
    "def mean_from_counts(edges, counts):\n",
    "    centers = 0.5*(edges[:-1]+edges[1:])\n",
    "    tot = counts.sum()\n",
    "    if tot <= 0: return float('nan')\n",
    "    return float(np.dot(centers, counts)/tot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e915446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: compare_plots_mpl_stack/spin_observables.csv\n"
     ]
    }
   ],
   "source": [
    "plt.style.use(hep.style.CMS)\n",
    "results = []\n",
    "for hname in hist_names:\n",
    "    edges, dat_counts = combine_data(hname)\n",
    "    if edges is None:\n",
    "        print('[skip] No data for', hname); continue\n",
    "    dat_err = np.sqrt(np.clip(dat_counts,0,None))\n",
    "    centers = 0.5*(edges[:-1]+edges[1:])\n",
    "    edges_mc, mc_arrays, mc_labels, mc_sum_counts, mc_sum_hist = stack_mc_numpy(hname)\n",
    "    if edges_mc is None:\n",
    "        print('[skip] No MC for', hname); continue\n",
    "    cmap = plt.get_cmap('tab20')\n",
    "    others = [lbl for lbl in mc_labels if lbl != 'TTTo2L2Nu_MC_2018']\n",
    "    color_map = {lbl: cmap(i/max(1,len(others)-1)) for i,lbl in enumerate(others)}\n",
    "    color_map['TTTo2L2Nu_MC_2018'] = 'red'\n",
    "    mc_colors = [color_map[lbl] for lbl in mc_labels]\n",
    "    fig, (ax, axr) = plt.subplots(nrows=2, sharex=True, gridspec_kw={'height_ratios':[3,1],'hspace':0.05}, figsize=(10,8), dpi=150)\n",
    "    hep.histplot(mc_arrays, bins=edges, stack=True, histtype='fill', label=mc_labels, color=mc_colors, ax=ax)\n",
    "    ax.errorbar(centers, dat_counts, yerr=dat_err, fmt='o', color='black', label='Data')\n",
    "    ax.set_ylabel('Events / bin')\n",
    "    hep.cms.label('Private Work', data=True, lumi=59.8, ax=ax)\n",
    "    ax.legend(loc='upper right', prop={'size':8}, handletextpad=0.2, labelspacing=0.2, columnspacing=0.5)\n",
    "    mc_sum = mc_sum_counts\n",
    "    mask = mc_sum > 0\n",
    "    ratio = np.divide(dat_counts, mc_sum, out=np.zeros_like(dat_counts), where=mask)\n",
    "    ratio_err = np.divide(dat_err, mc_sum, out=np.zeros_like(dat_err), where=mask)\n",
    "    axr.errorbar(centers[mask], ratio[mask], yerr=ratio_err[mask], fmt='o', color='black')\n",
    "    axr.axhline(1, color='gray', linestyle='--', linewidth=1)\n",
    "    axr.set_ylabel('Data/MC'); axr.set_xlabel(hname); axr.set_ylim(0.5,1.5)\n",
    "    fig.savefig(f\"{out_dir}/stack_{hname}.png\"); plt.close(fig)\n",
    "    if is_cos_hist(hname):\n",
    "        ch = channel_from_name(hname)\n",
    "        axis = axis_from_name(hname)\n",
    "        mean_data = mean_from_counts(edges, dat_counts)\n",
    "        if USE_ROOT and mc_sum_hist is not None:\n",
    "            mean_mc = float(mc_sum_hist.GetMean())\n",
    "        else:\n",
    "            mean_mc = mean_from_counts(edges, mc_sum_counts)\n",
    "        if 'times_Minus_' in hname:\n",
    "            C_data = (9.0/(alpha_l**2)) * mean_data\n",
    "            C_mc   = (9.0/(alpha_l**2)) * mean_mc\n",
    "            results.append([hname, ch, axis, 'Caa', mean_data, mean_mc, C_data, C_mc])\n",
    "        elif 'cosThetaPlus_' in hname:\n",
    "            P_data = (3.0/alpha_l) * mean_data\n",
    "            P_mc   = (3.0/alpha_l) * mean_mc\n",
    "            results.append([hname, ch, axis, 'Pa', mean_data, mean_mc, P_data, P_mc])\n",
    "import pandas as pd\n",
    "C_map_data = {ch:{'k':None,'r':None,'n':None} for ch in ['ee','mumu','emu','all']}\n",
    "C_map_mc   = {ch:{'k':None,'r':None,'n':None} for ch in ['ee','mumu','emu','all']}\n",
    "for hname,ch,axis,kind,mean_d,mean_m,val_d,val_m in results:\n",
    "    if kind=='Caa':\n",
    "        C_map_data[ch][axis]=val_d; C_map_mc[ch][axis]=val_m\n",
    "for ch in C_map_data:\n",
    "    cds=C_map_data[ch]; cms=C_map_mc[ch]\n",
    "    if all(v is not None for v in cds.values()):\n",
    "        D_data=(cds['k']+cds['r']+cds['n'])/3.0\n",
    "        results.append([f'{ch}_D',ch,'sum','D',float('nan'),float('nan'),D_data,float('nan')])\n",
    "    if all(v is not None for v in cms.values()):\n",
    "        D_mc=(cms['k']+cms['r']+cms['n'])/3.0\n",
    "        results.append([f'{ch}_D_mc',ch,'sum','D_MC',float('nan'),float('nan'),float('nan'),D_mc])\n",
    "df = pd.DataFrame(results, columns=['hname','channel','axis','kind','mean_data','mean_mc','value_data','value_mc'])\n",
    "csv_path = f\"{out_dir}/spin_observables.csv\"; df.to_csv(csv_path, index=False)\n",
    "print('Saved:', csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140e8bd6-888a-4799-9e83-44cb8c7c38b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4008a1d4-5909-499c-81c9-59f1db9225a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0615f790-62b6-4a1c-adb8-da5493f0486d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627125ad-8d98-4481-9f9d-043d29c1f2df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
